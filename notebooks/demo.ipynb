{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a65a76a-7546-4e5e-bc4f-f3a96bc074b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import unicodedata\n",
    "import gc\n",
    "\n",
    "import spacy\n",
    "import sqlite3\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bd3eba-757f-4ac0-b6f2-2c74a8edfe89",
   "metadata": {},
   "source": [
    "### Load Alias Table and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5e748f-2dff-43f0-99c6-80b602aa4915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>surface_form</th>\n",
       "      <th>normal_form</th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q23304137</td>\n",
       "      <td>karnemelksegat</td>\n",
       "      <td>Karnemelksegat</td>\n",
       "      <td>Karnemelksegat</td>\n",
       "      <td>meer in Noord-Holland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q23304137</td>\n",
       "      <td>karnemelksgat</td>\n",
       "      <td>Karnemelksgat</td>\n",
       "      <td>Karnemelksegat</td>\n",
       "      <td>meer in Noord-Holland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q23304529</td>\n",
       "      <td>zoel</td>\n",
       "      <td>Zoel</td>\n",
       "      <td>Zoel</td>\n",
       "      <td>rivier in Nederland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q23306241</td>\n",
       "      <td>kalkwerk</td>\n",
       "      <td>Kalkwerk</td>\n",
       "      <td>Kalkwerk</td>\n",
       "      <td>voormalig buurtschap in Groningen, Nederland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q59244527</td>\n",
       "      <td>roomgracht</td>\n",
       "      <td>Roomgracht</td>\n",
       "      <td>Roomgracht</td>\n",
       "      <td>voormalige gracht in Leiden, Nederland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         qid    surface_form     normal_form           label  \\\n",
       "0  Q23304137  karnemelksegat  Karnemelksegat  Karnemelksegat   \n",
       "1  Q23304137   karnemelksgat   Karnemelksgat  Karnemelksegat   \n",
       "2  Q23304529            zoel            Zoel            Zoel   \n",
       "3  Q23306241        kalkwerk        Kalkwerk        Kalkwerk   \n",
       "4  Q59244527      roomgracht      Roomgracht      Roomgracht   \n",
       "\n",
       "                                    description  \n",
       "0                         meer in Noord-Holland  \n",
       "1                         meer in Noord-Holland  \n",
       "2                           rivier in Nederland  \n",
       "3  voormalig buurtschap in Groningen, Nederland  \n",
       "4        voormalige gracht in Leiden, Nederland  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alias_table = pd.read_pickle(\"../../knowledge_base/alias_table.pkl\")\n",
    "nlp = spacy.load(\"../../output/model-best\")\n",
    "cross_encoder_marco = CrossEncoder(\"../../bert_output/ms-marco-MiniLM/checkpoint-279\")\n",
    "cross_encoder_bertje = CrossEncoder(\"../../bert_output/bert-base-dutch/checkpoint-279\")\n",
    "\n",
    "nlp.add_pipe('sentencizer')\n",
    "alias_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9893853-6fe7-4c7a-985f-2cf970063137",
   "metadata": {},
   "source": [
    "### Index Alias Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e71a7b5a-7eeb-469c-b63d-46453c02cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect(':memory:')\n",
    "cur = db.cursor()\n",
    "\n",
    "# Create surface form table\n",
    "cur.execute('create virtual table kb using fts5(qid UNINDEXED, surface_form, normal_form UNINDEXED, label UNINDEXED, description UNINDEXED, tokenize=\"porter unicode61\");')\n",
    "\n",
    "# populate form table table\n",
    "cur.executemany(\n",
    "    'insert into kb (qid, surface_form, normal_form, label, description) values (?,?,?,?,?);',\n",
    "    alias_table[['qid', 'surface_form', 'normal_form','label', 'description']].to_records(index=False))\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8dd4a-16de-406a-960d-fe9321d447dc",
   "metadata": {},
   "source": [
    "### Load Woogle data\n",
    "It is recommended to only load one dataframe to save RAM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a6e8e6-09e2-4878-844a-2927adc72f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../../woo_data/2b_clean.csv\")\n",
    "df2 = pd.read_csv(\"../../woo_data/2c_clean.csv\")\n",
    "df3 = pd.read_csv(\"../../woo_data/2e-b_clean.csv\")\n",
    "df4 = pd.read_csv(\"../../woo_data/2i_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac88db89-92e6-4d6a-a9e2-1d9db0d2379c",
   "metadata": {},
   "source": [
    "### Sample (optional) and group documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5eaafd4-112f-4a73-be7c-1eff9927171d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>foi_documentId</th>\n",
       "      <th>foi_bodyTextOCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nl.oorg10002.2b.1997.29-2333-2333.doc.1</td>\n",
       "      <td>Voorzitter: Weisglas Tegenwoordig zijn 107 led...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nl.oorg10002.2b.1998.21-1356-1379.doc.1</td>\n",
       "      <td>daarin wordt gevraagd om een zo spoedig mogeli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nl.oorg10002.2b.2015.61-12.doc.1</td>\n",
       "      <td>12 Stemmingen overige moties Rapport Onderzoek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nl.oorg10002.2b.2019.102-17.doc.1</td>\n",
       "      <td>17 Stemmingen moties Ontwerpbesluit maatregele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nl.oorg10002.2b.2023.18-6.doc.1</td>\n",
       "      <td>6 Afrikastrategie Voorzitter: Kamminga Afrikas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            foi_documentId  \\\n",
       "0  nl.oorg10002.2b.1997.29-2333-2333.doc.1   \n",
       "1  nl.oorg10002.2b.1998.21-1356-1379.doc.1   \n",
       "2         nl.oorg10002.2b.2015.61-12.doc.1   \n",
       "3        nl.oorg10002.2b.2019.102-17.doc.1   \n",
       "4          nl.oorg10002.2b.2023.18-6.doc.1   \n",
       "\n",
       "                                     foi_bodyTextOCR  \n",
       "0  Voorzitter: Weisglas Tegenwoordig zijn 107 led...  \n",
       "1  daarin wordt gevraagd om een zo spoedig mogeli...  \n",
       "2  12 Stemmingen overige moties Rapport Onderzoek...  \n",
       "3  17 Stemmingen moties Ontwerpbesluit maatregele...  \n",
       "4  6 Afrikastrategie Voorzitter: Kamminga Afrikas...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_documents(df, n_samples, seed=42):\n",
    "    sampled_doc_ids = df['foi_documentId'].drop_duplicates().sample(n=n_samples, random_state=seed)\n",
    "    sampled_pages = df[df['foi_documentId'].isin(sampled_doc_ids)].copy()\n",
    "    return sampled_pages\n",
    "\n",
    "n = 10\n",
    "df = sample_documents(df1, n)\n",
    "\n",
    "df = df.groupby(\"foi_documentId\")['foi_bodyTextOCR']\\\n",
    "    .apply(lambda pages: \" \".join(pages.dropna().astype(str)))\\\n",
    "    .reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e2795d-81d1-459b-af92-46d879ad7b7c",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea72efc1-5b8a-4217-bdd2-cdfb6bef7f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_unicode(text):\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    text = ''.join([c for c in text if not unicodedata.combining(c)])\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    text = normalize_unicode(str(text))\n",
    "    text = re.sub(r'-\\s+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    tokens = text.split()\n",
    "    return ' '.join(token.strip() for token in tokens).lower()\n",
    "\n",
    "def prepare_candidates(candidates):\n",
    "    fts_scores = []\n",
    "    labels = []\n",
    "    descriptions = []\n",
    "\n",
    "    for i, (qid, rank, label, surface_from, desc) in enumerate(candidates):\n",
    "        fts_scores.append(rank)\n",
    "        labels.append(label)\n",
    "        descriptions.append(f\"{label} - {desc}\")\n",
    "\n",
    "    return fts_scores, labels, descriptions\n",
    "\n",
    "def normalize_scores(scores, min_val, max_val):\n",
    "    return (scores - min_val) / (max_val - min_val)\n",
    "\n",
    "def compute_final_scores(encoder_scores, fts_scores, alpha):\n",
    "    fts_min, fts_max = 4.2948, 25.2106\n",
    "    encoder_min, encoder_max = -11.0917, 6.2494\n",
    "\n",
    "    fts_scores_norm = normalize_scores(np.abs(fts_scores), fts_min, fts_max)\n",
    "    encoder_scores_norm = normalize_scores(encoder_scores, encoder_min, encoder_max)\n",
    "\n",
    "    return alpha * encoder_scores_norm + (1 - alpha) * fts_scores_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b11035-7acf-45e0-ac75-e555308d5f8f",
   "metadata": {},
   "source": [
    "### Named Entity Recognition and Entity Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd0ccdc4-64ab-4e5f-9e17-6e0f87e468bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def named_entity_recognition(text):\n",
    "    doc = nlp(text)\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append({\n",
    "            'mention': ent.text,\n",
    "            'context': ent.sent.text,\n",
    "            'start': ent.start\n",
    "        })\n",
    "    return entities\n",
    "\n",
    "def candidate_generation(mention, limit=15, window=10):\n",
    "    terms = mention.split()\n",
    "    if len(terms) >= 2:\n",
    "        quoted_terms = ' '.join(f'\"{t}\"' for t in terms)\n",
    "        query = f\"NEAR({quoted_terms}, {window})\"\n",
    "    else:\n",
    "        query = f\"surface_form:{mention}\"\n",
    "\n",
    "    qids = []\n",
    "    res = cur.execute(f\"\"\"\n",
    "        SELECT qid, MIN(rank) as best_rank, label, normal_form, description\n",
    "        FROM kb\n",
    "        WHERE surface_form MATCH ?\n",
    "        GROUP BY qid\n",
    "        ORDER BY best_rank\n",
    "        LIMIT ?\n",
    "        \"\"\", (query, limit)).fetchall()\n",
    "\n",
    "    for candidate in res:\n",
    "        qids.append(candidate[0])\n",
    "\n",
    "    return qids, res\n",
    "\n",
    "def ranking(qids, candidates, context, alpha):\n",
    "    if len(qids) == 0:\n",
    "        return None\n",
    "\n",
    "    fts_scores, labels, descriptions = prepare_candidates(candidates)\n",
    "\n",
    "    pairs = [(context, cand) for cand in descriptions]\n",
    "    encoder_scores = np.array(cross_encoder_marco.predict(pairs)) # Select re-ranking model\n",
    "    fts_scores = abs(np.array(fts_scores))\n",
    "\n",
    "    final_scores = compute_final_scores(encoder_scores, fts_scores, alpha)\n",
    "\n",
    "    best_idx = np.argmax(final_scores)\n",
    "    return qids[best_idx], labels[best_idx], final_scores[best_idx]\n",
    "\n",
    "def entity_linking(mention, context, limit=10, alpha=0.55, threshold=0.55): # Select hyperparameters\n",
    "    entity_clean = clean_text(mention)\n",
    "    qids, candidates = candidate_generation(entity_clean, limit)\n",
    "    result = ranking(qids, candidates, context, alpha)\n",
    "\n",
    "    if result is None:\n",
    "        return 'NILL'\n",
    "\n",
    "    qid, label, score = result\n",
    "    if score > threshold:\n",
    "        return qid #Change to 'label' to return page titles \n",
    "    else:\n",
    "        return 'NILL'\n",
    "\n",
    "def return_entities(text):\n",
    "    if len(text) > 200000: # Documents with high number of tokens can overload the RAM\n",
    "        return []\n",
    "\n",
    "\n",
    "    entities = named_entity_recognition(text)\n",
    "    entities_norm = []\n",
    "\n",
    "    for entity in entities:\n",
    "        mention = entity['mention']\n",
    "        context = entity['context']\n",
    "        start = entity['start']\n",
    "        linked = entity_linking(mention, context)\n",
    "        if linked != 'NILL':\n",
    "            entities_norm.append({\n",
    "                'entity': linked,\n",
    "                'start': start\n",
    "            })\n",
    "\n",
    "\n",
    "    return entities_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e961a10d-a5e3-4a67-95e0-b7a211670693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|███████████████████████████████████████████████████████████████| 2/2 [04:54<00:00, 147.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>foi_documentId</th>\n",
       "      <th>foi_bodyTextOCR</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nl.oorg10002.2b.1997.29-2333-2333.doc.1</td>\n",
       "      <td>Voorzitter: Weisglas Tegenwoordig zijn 107 led...</td>\n",
       "      <td>[{'entity': 'Q2368020', 'start': 15}, {'entity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nl.oorg10002.2b.1998.21-1356-1379.doc.1</td>\n",
       "      <td>daarin wordt gevraagd om een zo spoedig mogeli...</td>\n",
       "      <td>[{'entity': 'Q667680', 'start': 24}, {'entity'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nl.oorg10002.2b.2015.61-12.doc.1</td>\n",
       "      <td>12 Stemmingen overige moties Rapport Onderzoek...</td>\n",
       "      <td>[{'entity': 'Q752', 'start': 366}, {'entity': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nl.oorg10002.2b.2019.102-17.doc.1</td>\n",
       "      <td>17 Stemmingen moties Ontwerpbesluit maatregele...</td>\n",
       "      <td>[{'entity': 'Q275441', 'start': 162}, {'entity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nl.oorg10002.2b.2023.18-6.doc.1</td>\n",
       "      <td>6 Afrikastrategie Voorzitter: Kamminga Afrikas...</td>\n",
       "      <td>[{'entity': 'Q22001627', 'start': 252}, {'enti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            foi_documentId  \\\n",
       "0  nl.oorg10002.2b.1997.29-2333-2333.doc.1   \n",
       "1  nl.oorg10002.2b.1998.21-1356-1379.doc.1   \n",
       "2         nl.oorg10002.2b.2015.61-12.doc.1   \n",
       "3        nl.oorg10002.2b.2019.102-17.doc.1   \n",
       "4          nl.oorg10002.2b.2023.18-6.doc.1   \n",
       "\n",
       "                                     foi_bodyTextOCR  \\\n",
       "0  Voorzitter: Weisglas Tegenwoordig zijn 107 led...   \n",
       "1  daarin wordt gevraagd om een zo spoedig mogeli...   \n",
       "2  12 Stemmingen overige moties Rapport Onderzoek...   \n",
       "3  17 Stemmingen moties Ontwerpbesluit maatregele...   \n",
       "4  6 Afrikastrategie Voorzitter: Kamminga Afrikas...   \n",
       "\n",
       "                                            entities  \n",
       "0  [{'entity': 'Q2368020', 'start': 15}, {'entity...  \n",
       "1  [{'entity': 'Q667680', 'start': 24}, {'entity'...  \n",
       "2  [{'entity': 'Q752', 'start': 366}, {'entity': ...  \n",
       "3  [{'entity': 'Q275441', 'start': 162}, {'entity...  \n",
       "4  [{'entity': 'Q22001627', 'start': 252}, {'enti...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "results = []\n",
    "\n",
    "total_batches = len(df) // batch_size + 1\n",
    "\n",
    "for batch_idx in tqdm(range(total_batches), desc=\"Processing Batches\"):\n",
    "    start = batch_idx * batch_size\n",
    "    end = min(start + batch_size, len(df))\n",
    "    \n",
    "    batch = df.iloc[start:end].copy()\n",
    "    batch_results = []\n",
    "    \n",
    "    for text in batch['foi_bodyTextOCR']:\n",
    "        try:\n",
    "            ents = return_entities(text)\n",
    "        except Exception as e:\n",
    "            # print(f\"Error processing text: {e}\")\n",
    "            ents = []\n",
    "        batch_results.append(ents)\n",
    "    \n",
    "    batch['entities'] = batch_results\n",
    "    results.append(batch)\n",
    "    \n",
    "    del batch, batch_results\n",
    "    gc.collect()\n",
    "\n",
    "df_results = pd.concat(results, ignore_index=True)\n",
    "df_results.head()\n",
    "\n",
    "# Optional: write to pkl\n",
    "# df_results.to_pickle(\"results.pkl\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888dffa2-46a9-4987-a512-a1c48c63f737",
   "metadata": {},
   "source": [
    "### Co-occurrence Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c58a39a6-6681-4bc1-af1f-41cfa4e725eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_network_documents(df):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        entity_list = row['entities']\n",
    "        \n",
    "        if not entity_list or len(entity_list) < 1:\n",
    "            continue\n",
    "    \n",
    "        for ent in entity_list:\n",
    "            if ent['entity'] is not None:\n",
    "                G.add_node(ent['entity'])\n",
    "                \n",
    "        for ent1, ent2 in combinations(entity_list, 2):\n",
    "            label1 = ent1['entity']\n",
    "            label2 = ent2['entity']\n",
    "            \n",
    "            if label1 == label2:\n",
    "                continue \n",
    "            \n",
    "            if G.has_edge(label1, label2):\n",
    "                G[label1][label2][\"weight\"] += 1\n",
    "            else:\n",
    "                G.add_edge(label1, label2, weight=1)\n",
    "\n",
    "    return G\n",
    "\n",
    "def make_network_proximity(df, k=50):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        entity_list = row['entities']\n",
    "        \n",
    "        if not entity_list or len(entity_list) < 1:\n",
    "            continue\n",
    "    \n",
    "        for ent in entity_list:\n",
    "            G.add_node(ent['entity'])\n",
    "    \n",
    "        for ent1, ent2 in combinations(entity_list, 2):\n",
    "            if ent1['entity'] == ent2['entity']:\n",
    "                continue \n",
    "    \n",
    "            distance = abs(ent1['start'] - ent2['start'])\n",
    "            if distance <= k:\n",
    "                if G.has_edge(ent1['entity'], ent2['entity']):\n",
    "                    G[ent1['entity']][ent2['entity']]['weight'] += 1\n",
    "                else:\n",
    "                    G.add_edge(ent1['entity'], ent2['entity'], weight=1)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cfa306e-56e7-40ef-a8c6-5d843231de5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes in graph 1: 146\n",
      "Edges in graph 1: 856\n"
     ]
    }
   ],
   "source": [
    "# Optional: read pkl\n",
    "# df_results = pd.read_pickle(\"results.pkl\")\n",
    "\n",
    "graph = make_network_proximity(df_results)\n",
    "\n",
    "print(\"Nodes in graph 1:\", graph.number_of_nodes())\n",
    "print(\"Edges in graph 1:\", graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90df6a91-add3-45fb-9e3a-8ca828bf47ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes in graph 1: 41\n",
      "Edges in graph 1: 76\n"
     ]
    }
   ],
   "source": [
    "def filter_edges(graph):\n",
    "    G = nx.Graph()\n",
    "    filtered_edges = [(u, v, d) for u, v, d in graph.edges(data=True) if d.get('weight', 0) > 1]\n",
    "    G.add_edges_from(filtered_edges)\n",
    "    return G\n",
    "\n",
    "graph = filter_edges(graph)\n",
    "\n",
    "print(\"Nodes in graph 1:\", graph.number_of_nodes())\n",
    "print(\"Edges in graph 1:\", graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98e6f208-0b1e-4422-b435-7026fd701c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: k-core decomposition\n",
    "# graph = nx.k_core(graph, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcec9f28-9f43-46ed-ba7b-12c7a1b7a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: write to node and edge dataframes\n",
    "nodes = pd.DataFrame({'Id': list(graph.nodes)})\n",
    "\n",
    "edges_proximity = nx.to_pandas_edgelist(graph)\n",
    "\n",
    "edges_proximity = edges_proximity.rename(columns={'source': 'Source', 'target': 'Target', 'width': 'Weight'})\n",
    "\n",
    "# nodes.to_csv('nodes.csv', index=False)\n",
    "# edges_proximity.to_csv('edges_proximity.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
